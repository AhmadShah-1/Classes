


highly nonlinear activation functions are better for hidden layers

For images, input layer reduce dimensions until the output layer is reached
For timeseries or sensor data, you can still flatten it into a input matrix, very  good for highly non-linear relationships  

Natural language processing is unstructured data. As for numerical input  we can use numerical matrix  and neural networks, with sequential and  nonlinear mapping. But for natural language we need a different approach.


![[Pasted image 20260218092644.png]]
![[Pasted image 20260218092716.png]]
Token is smaller than a word
Token < Word

1 token  =   about 0.6 tokens