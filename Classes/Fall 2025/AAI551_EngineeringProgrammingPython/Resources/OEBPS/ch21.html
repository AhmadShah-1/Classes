<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xml:lang="en"
lang="en"
xmlns="http://www.w3.org/1999/xhtml"
xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<title>Learning Python, 6th Edition</title>
<link rel="stylesheet" type="text/css" href="override_v1.css"/>
<link rel="stylesheet" type="text/css" href="epub.css"/>
</head>
<body>
<div id="book-content">
<div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 21. The Benchmarking Interlude"><div class="chapter" id="the_benchmarking_interlude">
<h1><span class="label">Chapter 21. </span>The Benchmarking Interlude</h1>
<p>Now that we’ve fully explored function coding and iteration tools, we’re going to take a short side trip to put both of them to work. This chapter closes out the function part of this book with a larger case study that times the relative performance of the iteration tools we’ve met so far, in both standard Python and one of its alternatives.</p>
<p>Along the way, this case study surveys Python’s code-timing tools, discusses benchmarking techniques in general, and develops code that’s more realistic and useful than most of what we’ve seen up to this point. We’ll also measure the speed of code we’ve used—data points that may or may not be significant, depending on your programs’ goals.</p>
<p>Finally, because this is the last chapter in this part of the book, we’ll close with the usual sets of “gotchas” and exercises to help you start coding the ideas you’ve read about. First, though, let’s have some fun with tangible Python code.</p>
<section data-type="sect1" data-pdf-bookmark="Benchmarking with Homegrown Tools"><div class="sect1" id="benchmarking_with_homegrown_tools">
<h1>Benchmarking with Homegrown Tools</h1>
<p>We’ve met quite a few iteration alternatives <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" id="id3328"></a>in this book. Like much in programming, they represent trade-offs—in terms of both subjective factors like expressiveness, and more objective criteria such as performance. Part of your job as a programmer and engineer is selecting tools based on factors like these.</p>
<p>In terms of performance, this book has mentioned a few times that list comprehensions and <code>map</code> calls sometimes have a speed advantage over <code>for</code> loop statements. It has also noted that sorting speed varies with ordering, and the generator functions and expressions of the preceding chapter tend to be slower than all the others, though they minimize memory space requirements and don’t delay the caller for result generation when there are many results to generate.</p>
<p>All that is generally true today in common usage. That being said, benchmarking comes with some big caveats: both code structure and host architecture can influence speed arbitrarily; Python’s performance can vary over time because its internals are constantly being changed and optimized; and the speed of alternative Pythons may differ widely. As noted in <a data-type="xref" href="ch02.html#how_python_runs_programs">Chapter 2</a>, for example, the standard <em>CPython</em> may adopt a standard JIT in the future which could change its speed in some contexts, and optimized Pythons like <em>PyPy</em> have very difference performance profiles.</p>
<p>In short, if you want to verify speed for yourself, you need to time your code, on your own device, with the Python or Pythons you plan to use, and in the here and now. That’s a lot of qualifiers, but benchmarking is an empirical task.</p>
<section data-type="sect2" data-pdf-bookmark="Timer Module: Take 1"><div class="sect2" id="timing_module_take_one">
<h2>Timer Module: Take 1</h2>
<p>Luckily, Python makes it easy to time <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timing module" data-tertiary="example" id="tmktmdx"></a>code with custom tools—though perhaps deceptively so. For example, to get the total time taken to run multiple calls to a function with arbitrary positional arguments, <a data-type="xref" href="#example_twoone_onedot_timerzerodotpy">Example 21-1</a>’s function coded in a module file might suffice as a first cut.</p>
<div data-type="example" id="example_twoone_onedot_timerzerodotpy">
<h5><span class="label">Example 21-1. </span>timer0.py</h5>
<pre data-type="programlisting">"Simplistic timing function"

import time
def timer(func, *args):                    <code><em># Any positional arguments (only)</em></code>
    start = time.perf_counter()
    for i in range(100_000):               <code><em># Hardcoded reps, range() timed</em></code>
        func(*args)
    return time.perf_counter() - start     <code><em># Total elapsed time in seconds</em></code></pre>
</div>
<p>This function fetches time values from Python’s standard-library <code>time</code> module, and subtracts the system start time from the stop time after running 100,000 calls to the passed-in function with the passed-in arguments.</p>
<p>Time comes from <code>time.perf_counter</code>, which is defined to be a portable clock with the best resolution to measure a short duration. The difference between two calls is generally used for performance measurement, but includes time for sleeps and is system-wide time. The alternative <code>time.process_time</code> is per-process CPU time, and may also be useful in some roles. See Python’s manuals for more details; these calls replace the former and less portable <code>time.clock</code>, which was deprecated and dropped since this book’s prior edition (breaking most examples here!).</p>
<p>Apart from its <code>time</code> calls, the code in <a data-type="xref" href="#example_twoone_onedot_timerzerodotpy">Example 21-1</a> is straightforward and uses tools we’ve already met. When used on this book’s main development computer using macOS and CPython 3.12, its results are these in a REPL:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>from timer0 import timer</strong></code>
&gt;&gt;&gt; <code><strong>timer(pow, 2, 1000)</strong> </code>              <code><em># Time to call pow(2, 1000) 100k times</em></code>
0.08591239107772708
&gt;&gt;&gt; <code><strong>timer(str.upper, 'hack' * 100)</strong></code>    <code><em># Time to call 'hack...'.upper() 100k times</em></code>
0.04990812297910452</pre>
<p>Though functional and simple, the preceding timer is also fairly limited, and deliberately exhibits some classic mistakes in both function design and benchmarking. Among these, it:</p>
<ul>
<li><p>Hardcodes the <em>repetitions</em> count at 100k</p></li>
<li><p>Charges the cost of <code>range</code> to the tested function’s time</p></li>
<li><p>Doesn’t support <em>keyword</em> arguments in the tested function</p></li>
<li><p>Doesn’t give callers a way to <em>verify</em> that the tested function actually worked</p></li>
<li><p>Only gives <em>total</em> time, which might fluctuate on some busy host machines</p></li>
</ul>
<p>In other words, timing code is more complex than you might expect!</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Timer Module: Take 2"><div class="sect2" id="timer_module_take_two">
<h2>Timer Module: Take 2</h2>
<p>To be more general and accurate, let’s rewrite the preceding section’s code to define still simple but more useful <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="timer utility functions" id="id3329"></a><a contenteditable="false" data-type="indexterm" data-primary="timer utility functions" id="id3330"></a>timer utility functions we can both use to see how iteration alternative options stack up now, and apply to other timing needs in the future. These functions, in <a data-type="xref" href="#example_twoone_twodot_timerdotpy">Example 21-2</a>, are coded in a module file again so they can be used in a variety of programs, and have docstrings giving some basic usage details that <code>help</code> and PyDoc can display; see <a data-type="xref" href="ch15.html#the_documentation_interlude">Chapter 15</a> for tips on viewing the in-code documentation of this chapter’s timing modules.</p>
<div data-type="example" id="example_twoone_twodot_timerdotpy">
<h5><span class="label">Example 21-2. </span>timer.py</h5>
<pre data-type="programlisting">"""
Homegrown timing tools for arbitrary function calls.
Times one call, total of N, best of N, and best of totals of N.
Pass any number of positional and keyword arguments for each func. 
"""

import time
timer = time.perf_counter                         <code><em># See also time.process_time()</em></code>

def once(func, *pargs, **kargs):                  <code><em># Collect arguments for func</em></code>
    """
    Time to run func(...) one time.
    Returns (time, result).
    """
    start   = timer()
    result  = func(*pargs, **kargs)               <code><em># Unpack arguments for func</em></code>
    elapsed = timer() - start
    return (elapsed, result)                      <code><em># Return result to verify</em></code>

def total(reps, func, *pargs, **kargs):           <code><em># Collect arguments for func
</em></code>    """
    Total time to run func(...) reps times.
    Returns (total-time, last-result).
    """
    total = 0                                     <code><em># Don't charge range() time</em></code>
    for i in range(reps):
        time, result = once(func, *pargs, **kargs)
        total += time
    return (total, result)                        <code><em># Return last result to verify</em></code>

def bestof(reps, func, *pargs, **kargs):
    """
    Best time among reps runs of func(...).
    Returns (best-time, best-time-result).
    """
    return min(once(func, *pargs, **kargs) for i in range(reps))

def bestoftotal(reps1, reps2, func, *pargs, **kargs):
    """
    Best total time among reps1 runs of [reps2 runs of func(...)].
    Returns (best-total-time, best-total-time-last-result).
    """
    return min(total(reps2, func, *pargs, **kargs) for i in range(reps1))</pre>
</div>
<p>Operationally, this module implements both <em>total</em> and <em>best</em> times, and a <em>best of totals</em> that combines the other two. In each mode, it times calls to any subject function that takes any positional and keyword arguments, by fetching the start time, calling the function with arbitrary arguments, and subtracting the start time from the stop time. Here are the salient points to notice about how this version addresses the shortcomings of its predecessor:</p>
<ul>
<li><p>The <em>repetitions</em> count is no longer hardcoded, but passed in as a required argument (or arguments) before the test function and its own arguments, to allow repetitions to vary per call.</p></li>
<li><p>The <code>range</code> call’s construction and iteration costs are no longer charged to timed functions, because timing has been factored out to the separate <code>once</code> function that times just the subject function.</p></li>
<li><p>Any number of both positional and <em>keyword</em> arguments for the timed function are now collected and unpacked with starred-argument syntax. They must be sent individually, not in a sequence or dictionary, though callers can unpack argument collections into individual arguments with stars in the top-level call.</p></li>
<li><p>All functions in this module return one of the timed function’s <em>return values</em> so callers can verify that the function worked. The return value is provided in a two-item result tuple, along with the requested time result.</p></li>
<li><p>New best-of modes return <em>minimum</em> times to address fluctuations on the host device, per the next paragraph.</p></li>
</ul>
<p>This version’s functions also support multiple use cases: <code>once</code> times a single call for simple cases; <code>total</code> runs many calls, to allow time to accumulate for short-lived functions; <code>bestof</code> returns the minimum time among all single calls, to filter out the impacts of other activity on the host; and <code>bestoftotal</code> selects the minimum of nested total-time tests, to both apply a best-of filter and run many calls for functions too fast to produce meaningful times.</p>
<p>Importantly, the <code>min</code> calls in the best-of variants work to select the best and lowest time, because Python compares collections recursively (from left to right) as we’ve learned, and result tuples begin with <em>time</em>: because it’s first in these <code>(<em>time</em>, <em>result</em>)</code> tuples, time dominates and determines the <code>min</code> calls’ results:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>min(tup for tup in [(2.0, 3), (3.0, 3), (1.0, 3), (0.0, 3), (4.0, 3)])</strong></code>
(0.0, 3)</pre>
<p>From a larger perspective, because these functions are coded in a module file, they become generally useful tools anywhere we wish to import them. Modules and imports were introduced in <a data-type="xref" href="ch03.html#how_you_run_programs">Chapter 3</a>, and you’ll learn more about them in the next part of this book; for now, simply import the module and call its function to use one of this file’s timers. Its results on the same host and in a REPL are similar to its <em>timer0.py</em> predecessor, but are more robust:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>import timer       </strong>  </code>                         <code><em># Import file in this directory</em></code>
&gt;&gt;&gt; <code><strong>help(timer)</strong></code>                                   <code><em># Display module's docs nicely</em></code>
&gt;&gt;&gt; <code><strong>reps, text = 100_000, 'hack' * 100</strong></code>

&gt;&gt;&gt;<code> <strong>timer.once(pow, 2, 1000)[0]</strong></code>                   <code><em># Not useful for fast calls</em></code>
6.182119250297546e-06
<code><strong>&gt;&gt;&gt; timer.once(str.upper, text)</strong></code>                   <code><em># (time, result)</em></code>
(3.363005816936493e-06, 'HACKHACKHACK…<code><em>etc</em></code>…')

&gt;&gt;&gt; <code><strong>timer.total(reps, pow, 2, 1000)[0]</strong></code>            <code><em># Compare to timer0 results</em></code>
0.08979405369609594
&gt;&gt;&gt; <code><strong>timer.total(reps, str.upper, text)[0]</strong></code>         <code><em># (time, last call's result)</em></code>
0.050884191412478685 

&gt;&gt;&gt;<code> <strong>timer.bestof(50, pow, 2, 1000)[0]</strong>   </code>          <code><em># Not useful for fast calls</em></code>
1.6265548765659332e-06
&gt;&gt;&gt; <code><strong>timer.bestof(50, str.upper, text)[0]</strong></code>          <code><em># (best time, best time result)</em></code>
8.619390428066254e-07 

&gt;&gt;&gt; <code><strong>timer.bestoftotal(50, reps, pow, 2, 1000)[0]</strong></code>
0.07521858718246222
&gt;&gt;&gt; <code><strong>timer.bestoftotal(50, reps, str.upper, text)[0]</strong></code>
0.03947464330121875</pre>
<p>The last two calls here calculate the <em>best-of-totals</em> times—the lowest time among 50 runs, each of which computes the total time to call a function 100k times—roughly corresponding to the <code>total</code> times earlier in this listing, but repeated for a minimum that filters out host fluctuations (and sans an extra charge for <code>range</code>). The function used in these last two calls is really just a convenience that wraps <code>total</code> for better accuracy, but this is a common timing mode.</p>
<p>Note that <code>bestoftotal</code> might replace its <code>min</code> of <code>total</code> with code like the following to nest <code>total</code> in <code>bestof</code>:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>timer.bestof(50, timer.total, reps, str.upper, text)</strong></code>
(0.07037258706986904, (0.039281503297388554, 'HACKHACKHACK…<code><em>etc</em></code>…'))</pre>
<p>But this isn’t quite the same. For one thing, the result is nested tuples, reflecting the nested calls. For another, this really times the entire <code>total</code> function, not just the subject function it runs. The net effect charges an extra admin-code overhead that’s enough to skew the best-of time up, and make it larger than the best total time <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timing module" data-tertiary="example" data-startref="tmktmdx" id="id3331"></a>shown in the nested tuple. By using <code>min</code> of <code>total</code> instead, <code>bestoftotal</code> avoids timing this overhead skew. Subtle but true!</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Timing Runner and Script"><div class="sect2" id="timing_runner_and_script">
<h2>Timing Runner and Script</h2>
<p>Now, to time iteration tool speed (our original goal), we’ll write a script that defines and submits test <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timing module" data-tertiary="test functions" id="bmmktf"></a>functions to the <code>timer</code> module. To make it easy to code a variety of tests, let’s first define a utility module that does the heavy lifting as a reusable intermediary. <a data-type="xref" href="#example_twoone_threedot_timer_runnerdot">Example 21-3</a> defines a function named <code>runner</code> that takes any number of test functions as arguments and passes them off for timing to the <code>bestoftotal</code> function imported from <a data-type="xref" href="#example_twoone_twodot_timerdotpy">Example 21-2</a>.</p>
<div data-type="example" id="example_twoone_threedot_timer_runnerdot">
<h5><span class="label">Example 21-3. </span>timer_runner.py</h5>
<pre data-type="programlisting">"Run passed-in test functions with the timer.py module"

import timer, sys

def runner(*tests):
    results = []
    print('Python', sys.version.split()[0], 'on', sys.platform)

    <em># Time</em>
    for test in tests:
        besttime, result = timer.bestoftotal(10, 1000, test)
        results.append(result)
        print(f'{test.__name__:&lt;9}: '
              f'{besttime:.5f} =&gt; [{result[0]}…{result[-1]}]')

    <em># Verify</em>
    print('Results differ!'
           if any(result != results[0] for result in results[1:])
           else 'All results same.')</pre>
</div>
<p>Fine points here: this module’s <code>runner</code> function displays context with <code>sys</code> tools documented in Python’s manuals, and steps through all the passed-in functions, printing the <code>__name__</code> of each (as we’ve seen, this is a built-in attribute that gives a function’s name). The test-runner code also saves results to verify that they are all the same in a ternary expression at the very end of the process, to be sure we’re comparing apples to apples.</p>
<p>Last but not least, the script in <a data-type="xref" href="#example_twoone_fourdot_timer_testsdotpy">Example 21-4</a> defines the actual tests to be timed and passes them to the imported runner of <a data-type="xref" href="#example_twoone_threedot_timer_runnerdot">Example 21-3</a>, which hands them off to the imported timer of <a data-type="xref" href="#example_twoone_twodot_timerdotpy">Example 21-2</a>. We’ll run the file in <a data-type="xref" href="#example_twoone_fourdot_timer_testsdotpy">Example 21-4</a> as a top-level script to time the relative speeds of the various iteration codings we’ve studied in this book so far.</p>
<div data-type="example" id="example_twoone_fourdot_timer_testsdotpy">
<h5><span class="label">Example 21-4. </span>timer_tests.py</h5>
<pre data-type="programlisting">"Test the relative speed of iteration coding alternatives."

from timer_runner import runner
repslist = list(range(10_000))

def forLoop():
    res = []
    for x in repslist:
        res.append(abs(x))
    return res

def listComp():
    return [abs(x) for x in repslist]

def mapCall():
    return list(map(abs, repslist))              <code><em># Use list() to force results</em></code>

def genExpr():
    return list(abs(x) for x in repslist)        <code><em># Use list() to force results</em></code>

def genFunc():
    def gen():
        for x in repslist:
            yield abs(x)
    return list(gen())                           <code><em># Use list() to force results</em></code> 

runner(forLoop, listComp, mapCall, genExpr, genFunc)</pre>
</div>
<p>This script tests five alternative ways to build lists of results. In combination with the test runner, its reported times reflect some 100 million steps for each of the 5 test functions—each builds a list of 10,000 items 1,000 times, and this process is repeated 10 times to get the best-of times. Applying this for each of the 5 test functions yields a whopping 500 million total steps for the script at large (impressive but reasonable on most machines these days).</p>
<p>Notice how we have to run the results of the generator expression and function through the built-in <code>list</code> call to force them to yield all of their values; if we did not, we would just produce generators that never do any real work. We must do the same for the <code>map</code> result, since it is an iterable, on-demand object as well.</p>
<p>For similar reasons, the inner loops’ <code>range</code> result is hoisted out to the top of the module to remove its construction cost from total time, and wrapped in a <code>list</code> call so that its traversal cost isn’t skewed by being a generator. This may be overshadowed by the cost of the inner iterations’ loops, but it’s best to <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timing module" data-tertiary="test functions" data-startref="bmmktf" id="id3332"></a>remove as many variables as we can. For example, though <code>range</code> supports multiple scans, tests’ times inflate by some 25% if its <code>list</code> wrapper is removed.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Iteration Results"><div class="sect2" id="iteration_results">
<h2>Iteration Results</h2>
<p>When the top-level script of the prior <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" id="bchkitr"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" id="itrtbmk"></a>section is run under the standard CPython 3.12 on the same macOS host, it prints the following with total times in seconds—after cueing the <em>drum roll</em>, that is:</p>
<pre data-type="programlisting">$ <code><strong>python3 timer_tests.py</strong></code>
Python 3.12.2 on darwin
forLoop  : 0.26035 =&gt; [0...9999]
listComp : 0.20781 =&gt; [0...9999]
mapCall  : 0.14399 =&gt; [0...9999]
genExpr  : 0.41133 =&gt; [0...9999]
genFunc  : 0.41203 =&gt; [0...9999]
All results same.</pre>
<p>In short, <code>map</code> calls are faster than list comprehensions, which are quicker than <code>for</code> loops, and both generator expressions and functions come in last and roughly tied for slowest. Perhaps surprisingly, generator expressions run much slower than equivalent list comprehensions today. As warned in the prior chapter, although wrapping a generator expression in a <code>list</code> call makes it <em>functionally</em> equivalent to a list comprehension, the internal <em>implementations</em> of the two expressions appear to differ:</p>
<pre data-type="programlisting">return [abs(x) for x in repslist]            <code><em># 0.20 seconds</em></code>
return list(abs(x) for x in repslist)        <code><em># 0.41 seconds: differs internally</em></code></pre>
<p>We’re also effectively timing the <code>list</code> call for the generator test, but given that this does not seem to hamper <code>map</code>, it’s likely moot. Though the exact cause for the difference would require deeper analysis (and probably source code spelunking), this seems to make sense given that the generator expression must do extra work to save and restore its state during value production; the list comprehension does not, and runs quicker here and in other tests ahead.</p>
<section data-type="sect3" data-pdf-bookmark="Other Pythons’ results"><div class="sect3" id="other_pythonsapostrophe_results">
<h3>Other Pythons’ results</h3>
<p>For comparison, following are the same tests’ speed results on the same host using the current <em>PyPy</em>—the optimized Python implementation discussed in <a data-type="xref" href="ch02.html#how_python_runs_programs">Chapter 2</a>, whose current 7.3 release implements the Python 3.10 language. PyPy is roughly <em>5X</em> quicker than CPython here (and up to <em>10X</em>), though its timing results can vary widely if its JIT has not yet compiled code in full (and a future and currently hypothetical CPython JIT may or may not even the race):</p>
<pre data-type="programlisting">$ <code><strong>pypy3 timer_tests.py</strong> </code>
Python 3.10.14 on darwin
forLoop  : 0.04329 =&gt; [0...9999]
listComp : 0.01876 =&gt; [0...9999]
mapCall  : 0.04132 =&gt; [0...9999]
genExpr  : 0.08744 =&gt; [0...9999]
genFunc  : 0.08726 =&gt; [0...9999]
All results same.</pre>
<p>On PyPy alone, list comprehensions win the title in this test today, but generators still lose soundly, and the fact that all of PyPy’s results are so much quicker today seems the larger point here. On CPython, <code>map</code> is still quickest so far.</p>
<p>Interestingly, these results are very different than they were in this book’s prior edition on Windows under <em>CPython 3.3</em>—when generators placed in the middle of the pack between list comprehensions and <code>for</code> loops, <code>for</code> loops fared substantially worse than they do today, and the script had a different name for historical reasons:</p>
<pre data-type="programlisting">C:\code&gt; <code><strong>c:\python33\python timeseqs.py</strong></code>
3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]
forLoop  : 1.33290 =&gt; [0...9999]
listComp : 0.69658 =&gt; [0...9999]
mapCall  : 0.56483 =&gt; [0...9999]
genExpr  : 1.08457 =&gt; [0...9999]
genFunc  : 1.07623 =&gt; [0...9999]</pre>
<p>While these absolute times naturally reflect older and slower test hosts, these tools’ <em>relative</em> performance has clearly changed in the last 12 years—and probably should be expected to do so again in another dozen!</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="For more good times: Function calls and map"><div class="sect3" id="for_more_good_times_function_calls_and">
<h3>For more good times: Function calls and map</h3>
<p>All of the foregoing is true as advertised, but watch what happens when <a data-type="xref" href="#example_twoone_fivedot_timer_teststwodo">Example 21-5</a> performs <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" data-tertiary="function calls" id="bktrfcl"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" data-tertiary="function calls" id="trbmkfc"></a><a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" data-tertiary="map function" id="bktmfc"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" data-tertiary="map function" id="itrbkmp"></a><a contenteditable="false" data-type="indexterm" data-primary="function calls" data-secondary="benchmarks" id="fcbmk"></a><a contenteditable="false" data-type="indexterm" data-primary="map function" data-secondary="benchmarking" id="mpfcbmk"></a>an <em>inline</em> operation on each iteration, such as a <code>+</code> expression, instead of calling a built-in function like <code>abs</code>. Only the test functions’ operations (in bold) need to be modified here, and the imported and reused runner handles tests generically.</p>
<div data-type="example" id="example_twoone_fivedot_timer_teststwodo">
<h5><span class="label">Example 21-5. </span>timer_tests2.py</h5>
<pre data-type="programlisting">from timer_runner import runner
repslist = list(range(10_000))

def forLoop():
    res = []
    for x in repslist:
        res.append(<code><strong>x + 10</strong></code>)
    return res

def listComp():
    return [<code><strong>x + 10</strong></code> for x in repslist]

def mapCall():
    return list(map(<code><strong>(lambda x: x + 10)</strong></code>, repslist))

def genExpr():
    return list(<code><strong>x + 10</strong></code> for x in repslist)

def genFunc():
    def gen():
        for x in repslist:
            yield <code><strong>x + 10</strong></code>
    return list(gen())

runner(forLoop, listComp, mapCall, genExpr, genFunc)</pre>
</div>
<p>Now, <code>map</code> is <em>slower</em> than the <code>for</code> loop statements, despite the fact that the looping-statements version is larger in terms of code. This could either mean that the need to <em>call</em> a user-defined function makes <code>map</code> slower—or equivalently, that the <em>lack</em> of function calls makes the others quicker. On CPython 3.12 and the same host as before:</p>
<pre class="pagebreak-before" data-type="programlisting">$ <code><strong>python3 timer_tests2.py</strong></code>
Python 3.12.2 on darwin
forLoop  : 0.28682 =&gt; [10...10009]
listComp : 0.24389 =&gt; [10...10009]
mapCall  : 0.49622 =&gt; [10...10009]
genExpr  : 0.44047 =&gt; [10...10009]
genFunc  : 0.44476 =&gt; [10...10009]
All results same.</pre>
<p>These results have also been consistent in CPython: the prior edition’s Python 3.3 results on a slower machine were again relatively similar, discounting test machine differences. Because the interpreter optimizes so much internally, performance analysis of Python code like this is a very tricky affair. Without numbers, it’s virtually impossible to guess which method will perform the best; again, the best you can do is time your code with your test parameters.</p>
<p>In this case, what we can say is that on this Python, using a user-defined <code>lambda</code> function in <code>map</code> calls seems to slow its performance disproportionately (though <code>+</code> is also slower than a trivial <code>abs</code> across the board), and that list comprehensions run quickest in this case (though slower than <code>map</code> in some others). List comprehensions seem consistently faster than <code>for</code> loops, but even this must be qualified—the list comprehension’s relative speed might be affected by its extra syntax (e.g., <code>if</code> filters), Python changes, and usage modes we did not time here.</p>
<p>For deeper truth, <a data-type="xref" href="#example_twoone_sixdot_timer_teststhreed">Example 21-6</a> codes one last takeoff on our tests to apply a simple user-defined function in <em>all five</em> iterations timed. Again, we must only modify the relevant (and bold) bits of the test <span class="keep-together">functions</span> themselves.</p>
<div data-type="example" id="example_twoone_sixdot_timer_teststhreed">
<h5><span class="label">Example 21-6. </span>timer_tests3.py</h5>
<pre data-type="programlisting">from timer_runner import runner
repslist = list(range(10_000))

def <code><strong>F(x)</strong></code>: return x

def forLoop():
    res = []
    for x in repslist:
        res.append(<code><strong>F(x)</strong></code>)
    return res

def listComp():
    return [<code><strong>F(x)</strong></code> for x in repslist]

def mapCall():
    return list(map(<code><strong>F</strong></code>, repslist))

def genExpr():
    return list(<code><strong>F(x)</strong></code> for x in repslist)  

def genFunc():
    def gen():
        for x in repslist:
            yield <code><strong>F(x)</strong></code>
    return list(gen())

runner(forLoop, listComp, mapCall, genExpr, genFunc)</pre>
</div>
<p>When coded this way and run in CPython 3.12 on the same host again, <code>map</code> improves its relative times, and comes in second between list comprehensions and <code>for</code> loops—instead of being slower than all others as it was for <code>+</code>:</p>
<pre data-type="programlisting">$ <code><strong>python3 timer_tests3.py</strong> </code>
Python 3.12.2 on darwin
forLoop  : 0.36206 =&gt; [0...9999]
listComp : 0.31181 =&gt; [0...9999]
mapCall  : 0.35479 =&gt; [0...9999]
genExpr  : 0.50531 =&gt; [0...9999]
genFunc  : 0.50290 =&gt; [0...9999]
All results same.</pre>
<p>That is, <code>map</code> may be slower simply <em>because it requires function calls</em>, and function calls are relatively slow in general. Since <code>map</code> can’t avoid calling functions, it may lose by association, and the other iteration tools may win when they can use expressions instead. On the other hand, this hypothesis alone can’t explain the better showing for <code>map</code> in the <code>abs</code> results of the first <em>timer_tests.py</em>: calling <em>built-in</em> functions may be a special and fast case for <code>map</code> in CPython (a theory supported by <a data-type="xref" href="#conclusion_comparing_tools">“Conclusion: Comparing tools”</a> and <code>ord</code> at the end of this chapter’s benchmarking safari).</p>
<p>All this being said, performance should not be your primary concern when writing Python code—the first thing you should do to optimize Python code is to <em>not optimize Python code</em>! Write for readability and simplicity first, then optimize later, if and only if needed. It could very well be that any of the five iteration alternatives we’ve <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" data-startref="bchkitr" id="id3333"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" data-startref="itrtbmk" id="id3334"></a><a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" data-tertiary="function calls" data-startref="bktrfcl" id="id3335"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" data-tertiary="function calls" data-startref="trbmkfc" id="id3336"></a><a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="iteration" data-tertiary="map function" data-startref="bktmfc" id="id3337"></a><a contenteditable="false" data-type="indexterm" data-primary="iteration" data-secondary="benchmarking" data-tertiary="map function" data-startref="itrbkmp" id="id3338"></a><a contenteditable="false" data-type="indexterm" data-primary="function calls" data-secondary="benchmarks" data-startref="fcbmk" id="id3339"></a><a contenteditable="false" data-type="indexterm" data-primary="map function" data-secondary="benchmarking" data-startref="mpfcbmk" id="id3340"></a>timed is quick enough for the data sets your program needs to process; if so, program clarity should be the chief goal.</p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="More Module Mods"><div class="sect2" id="more_module_mods">
<h2>More Module Mods</h2>
<p>Our <em>timer.py</em> module works as designed, but it could be a bit more user-friendly. Most obviously, its functions require passing in repetition counts as first arguments, and provide no defaults for them—a minor point, perhaps, but less than ideal in a general-purpose tool. To do better, it could allow repetition counts to be passed in as <em>keyword</em> arguments with <em>defaults</em>, much the same way we did for the <code>print</code> emulators of <a data-type="xref" href="ch18.html#arguments">Chapter 18</a>.</p>
<p>Here, though, these arguments’ names would have to be distinct to avoid clashing with those of the timed function (e.g., <code>_reps</code> instead of <code>reps</code>). While we’re at it, the function object could also be a <em>positional-only</em> argument to prevent name <code>func</code> from clashing with a keyword argument of the same name in the timed subject. <a data-type="xref" href="#example_twoone_sevendot_timertwodotpy">Example 21-7</a> codes the required mods (sans docs for space). Review <a data-type="xref" href="ch18.html#arguments">Chapter 18</a>’s argument-ordering coverage for more insight.</p>
<div data-type="example" id="example_twoone_sevendot_timertwodotpy">
<h5><span class="label">Example 21-7. </span>timer2.py</h5>
<pre data-type="programlisting">"Use keyword-only arguments with defaults for reps, and positional-only for func."

import time
timer = time.perf_counter

def once(func, /, *pargs, **kargs):
    start   = timer()
    result  = func(*pargs, **kargs)
    elapsed = timer() - start
    return (elapsed, result)

def total(func, /, *pargs, _reps=100_000, **kargs):
    total = 0
    for i in range(_reps):
        time, result = once(func, *pargs, **kargs)
        total += time
    return (total, result)

def bestof(func, /, *pargs, _reps=5, **kargs):
    return min(once(func, *pargs, **kargs) for i in range(_reps))

def bestoftotal(func, /, *pargs, _reps1=50, **kargs):
    return min(total(func, *pargs, **kargs) for i in range(_reps1))    <code><em># _reps =&gt; **</em></code></pre>
</div>
<p>This version is not backward compatible: it uses different names and modes for repetition arguments, which means the <em>timer_runner.py</em> we wrote earlier would require a minor edit to use it (see the examples package’s <a class="orm:hideurl" href="https://learning-python.com/LP6E/Chapter21/"><em>timer2_*.py</em></a>). Otherwise, it works the same—compare its output on the same host with <em>timer.py</em>’s results listed at <a data-type="xref" href="#example_twoone_twodot_timerdotpy">Example 21-2</a>:</p>
<pre data-type="programlisting">$ <code><strong>python3</strong></code>
&gt;&gt;&gt; <code><strong>import timer2</strong></code>
&gt;&gt;&gt; <code><strong>timer2.total(pow, 2, 1000, _reps=100_000)[0]</strong></code>
0.0865794476121664
&gt;&gt;&gt; <code><strong>timer2.total(str.upper, 'hack' * 100, _reps=100_000)[0]</strong></code>
0.04620114527642727

&gt;&gt;&gt; <code><strong>timer2.bestoftotal(pow, 2, 1000, _reps1=50, _reps=100_000)[0]</strong></code>
0.07179990829899907
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(str.upper, 'hack' * 100, _reps1=50, _reps=100_000)[0]</strong></code>
0.0393348871730268</pre>
<p>This time, though, we can allow the functions’ repetition defaults to apply or not:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>timer2.total(str.upper, 'hack' * 100)[0]</strong></code>
0.047992002684623
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(str.upper, 'hack' * 100)[0]</strong></code>
0.03935634717345238
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(str.upper, 'hack' * 100, _reps=10_000)[0]</strong></code>
0.00393257150426507</pre>
<p>Notice how the <code>_reps</code> argument for <code>total</code>, if passed, in <code>bestoftotal</code> calls is propagated along in <code>**kargs</code> because it’s not matched otherwise. For more vetting of this, time user-defined functions with richer argument headers as in the following. Per the first four timings, passing keyword arguments to a timed function adds a small time cost for unpacking—an unavoidable overhead shared by the original <em>timer.py</em>, but irrelevant when collecting relative times:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def f(a, b, c=88, d=99): return(a, b, c, d)</strong></code>

&gt;&gt;&gt; <code><strong>f(1, 2)</strong></code>
(1, 2, 88, 99)
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, _reps1=50, _reps=100_000)</strong></code>
(0.014080120716243982, (1, 2, 88, 99))
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, c=66, d=77, _reps1=50, _reps=100_000)</strong></code>
(0.021575820166617632, (1, 2, 66, 77))

&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, c=66, d=77, _reps1=50)</strong></code>
(0.021694606635719538, (1, 2, 66, 77))
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, c=66, d=77, _reps=100_000)</strong></code>
(0.021556788589805365, (1, 2, 66, 77))

&gt;&gt;&gt; <code><strong>def f(a, *b, c=88, **d): return(a, b, c, d)</strong></code>

&gt;&gt;&gt; <code><strong>f(1, 2, 3, c=66, d=77, e=88)</strong></code>
(1, (2, 3), 66, {'d': 77, 'e': 88})
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, 3, c=66, d=77, e=88)</strong></code>
(0.030859854072332382, (1, (2, 3), 66, {'d': 77, 'e': 88}))

&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, 3, c=66, d=77, e=88, _reps1=10)</strong></code>
(0.030802161898463964, (1, (2, 3), 66, {'d': 77, 'e': 88}))
&gt;&gt;&gt; <code><strong>timer2.bestoftotal(f, 1, 2, 3, c=66, d=77, e=88, _reps=10_000)</strong></code>
(0.0030745575204491615, (1, (2, 3), 66, {'d': 77, 'e': 88}))</pre>
<p>Beyond this, custom benchmarking code is fun but open ended, and this section must stop here for space. As next steps, you might modify the timing script to measure the speed of <em>set and dictionary</em> comprehensions and their <code>for</code> equivalents (open questions we’ll return to ahead); explore Python’s <span class="keep-together"><code>profile</code></span> and <code>cProfile</code> modules (tools that create full-program profiles instead of focused benchmarks); or explore Python’s <code>timeit</code> module, which works much like some of this chapter’s homegrown code, and offers extra options—as you’ll learn in the next section.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><em>Decorator timers preview</em>: Notice how <a contenteditable="false" data-type="indexterm" data-primary="decorator timers" id="id3341"></a>we must pass functions into the timers manually here. In <a data-type="xref" href="ch39.html#decorators">Chapter 39</a>, we’ll code <em>decorator</em>-based timer alternatives with which timed functions are called normally, but require extra <code>@</code> preamble syntax where defined. Decorators may be more useful to instrument functions with timing logic when they are already being used within a larger system, and don’t as easily support the specific test-call patterns assumed here—when decorated, <em>every</em> call to the function runs the timing logic, which is either a plus or minus depending on your goals.</p>
</div>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Benchmarking with Python’s timeit"><div class="sect1" id="benchmarking_with_pythonapostrophes_tim">
<h1>Benchmarking with Python’s timeit</h1>
<p>The preceding section used custom timing <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timeit module" id="bchktmdl"></a>functions to compare code speed. As teased there, the Python standard library also ships with a module named <code>timeit</code> that can be used in similar ways, but offers added flexibility, with support for timing code strings in addition to functions, as well as a command-line mode.</p>
<p>As usual in Python, it’s important to understand fundamental principles like those illustrated in the prior section. Python’s “batteries included” approach means you’ll usually find precoded options for most goals, though you still need to know the ideas underlying them to choose and use them properly. Indeed, the <code>timeit</code> module is a prime example of this—it’s had a history of being misused by newcomers who didn’t yet understand the concepts it embodies. Now that we’ve learned the basics, though, let’s move ahead to a tool that can automate much of our work.</p>
<section data-type="sect2" data-pdf-bookmark="Basic timeit Usage"><div class="sect2" id="basic_timeit_usage">
<h2>Basic timeit Usage</h2>
<p>Let’s start with this <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="callable objects" id="id3342"></a><a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="statement strings" id="id3343"></a>module’s fundamentals before leveraging them in larger scripts. With <code>timeit</code>, tests are specified by either <em>callable objects</em> or <em>statement strings</em>; the latter can hold multiple statements if they use <code>;</code> separators or <code>\n</code> characters for line breaks, and spaces or tabs to indent statements in nested blocks (e.g., <code>\n\t</code>). Tests may also give setup actions, and can be launched from both <em>command lines</em> and <em>API calls</em>, and from both scripts and the REPL.</p>
<section data-type="sect3" data-pdf-bookmark="API-calls mode"><div class="sect3" id="api_calls_mode">
<h3>API-calls mode</h3>
<p>For example, the <code>timeit</code> module’s <code>repeat</code> call returns a list giving the total time taken <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="API-calls mode" id="id3344"></a>to run a test a <code>number</code> of times, for each of <code>repeat</code> runs—the <code>min</code> of this list yields the best time among the runs, and helps filter out system load fluctuations that can otherwise skew timing results artificially high (like our earlier <code>bestoftotal</code>). Code to be timed is passed to the <code>stmt</code> keyword (or first positional) argument, and may be a string or no-argument function.</p>
<p>The following shows this call in action in REPLs on macOS, timing a list comprehension on both <span class="keep-together"><em>CPython 3.12</em></span> and the optimized <em>PyPy</em> implementation of Python described in <a data-type="xref" href="ch02.html#how_python_runs_programs">Chapter 2</a> (as earlier, its tested 7.3 release implements the Python 3.10 language). The results here give the best total time in seconds among 5 runs that each execute the code string 1,000 times; the code string itself constructs a 1,000-item list of integers each time through (<code>timeit</code> also has reasonable defaults for repeat counts, but being explicit ensures comparability):</p>
<pre data-type="programlisting">$ <code><strong>python3</strong></code>
&gt;&gt;&gt; <code><strong>import timeit</strong></code>
&gt;&gt;&gt; <code><strong>min(timeit.repeat(stmt='[x ** 2 for x in range(1000)]', number=1000, repeat=5))</strong></code>
0.05187674192711711

$ <code><strong>pypy3</strong></code>
&gt;&gt;&gt;&gt; <code><strong>import timeit</strong></code>
&gt;&gt;&gt;&gt; <code><strong>min(timeit.repeat(stmt='[x ** 2 for x in range(1000)]', number=1000, repeat=5))</strong></code>
0.00252467580139637</pre>
<p>You’ll notice that PyPy checks in at <em>20X</em> faster than CPython 3.12. This is a small artificial benchmark, of course, but stunning nonetheless, and reflects a relative speed ranking that is generally supported by other tests run in this book (though CPython will still beat PyPy on some types of code ahead, and again, may improve with a future JIT). To be fair, this particular test measures the speed of both a list comprehension and integer math, but integer math is ubiquitous in Python code, and PyPy’s win is larger on noninteger tests (try squaring a float to see for yourself).</p>
<p>These results also differ from the preceding section’s relative version speeds, where PyPy was some <em>10X</em> quicker for list comprehensions. Apart from the different type of code being timed here, the different coding structure inside <code>timeit</code> may have an effect too—for code strings like those tested here, <code>timeit</code> builds, compiles, and executes a function <code>def</code> statement string that embeds the test string, thereby avoiding a function call per inner loop. This is irrelevant from a relative-speed perspective, though: times from the same given tool are comparable.</p>
<p>You’ll also notice that code to be timed is a <em>string</em> here. As you’ll see ahead, this requires manually coded line breaks and indentation in some usage modes, and all code to be timed this way must conform to Python’s rules for string literals, quotes, and escapes. For instance, a code string cannot embed the same quotes used to enclose it without also escaping them. You can avoid this potential downside by timing callables, though they’re limited to zero arguments.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Command-line mode"><div class="sect3" id="command_line_mode">
<h3>Command-line mode</h3>
<p>The <code>timeit</code> module also can <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="command-line mode" id="tmtmmld"></a>be run as a script from a command line—either by explicit pathname, or, more portably, automatically located on the module search path with Python’s <code>–m</code> switch (we used this earlier to launch PyDoc in <a data-type="xref" href="ch15.html#the_documentation_interlude">Chapter 15</a> and IDLE in <a data-type="xref" href="ch03.html#how_you_run_programs">Chapter 3</a>). In this mode, you’ll need to <em>quote or escape</em> Python code in the command line per your console shell’s rules; double quotes are generally portable, but this also qualifies as a potential downside.</p>
<p>Also in this mode, <code>timeit</code> reports the average time for a <em>single</em> <code>–n</code> loop, in either “usec” microseconds (millionths), “msec” milliseconds (thousandths), “sec” seconds, or “nsec” nanoseconds; to compare results here to the total time values reported by API calls, multiply by the number of loops run—51 usec here * 1,000 loops is 51k usec, 51 msec, and 0.051 seconds in total time. For CPython 3.12 on macOS:</p>
<pre data-type="programlisting">$ <code><strong>python3 -m timeit -n 1000 "[x ** 2 for x in range(1000)]"</strong></code>
1000 loops, best of 5: 51.9 usec per loop

$ <code><strong>python3 -m timeit -n 1000 -r 50 "[x ** 2 for x in range(1000)]"</strong></code>
1000 loops, best of 50: 51.8 usec per loop</pre>
<p>As another example, we can use command lines to verify that choice of timer call doesn’t impact speed comparisons run in this chapter so far. <code>timeit</code> uses <code>time.perf_counter</code> by default but its <code>-p</code> flag instructs it to instead use <code>time.process_time</code>, both discussed earlier (spoiler: as tested, there’s no discernible difference):</p>
<pre data-type="programlisting">$ <code><strong>python3 -m timeit -p -n 1000 -r 50 "[x ** 2 for x in range(1000)]"</strong></code>
1000 loops, best of 50: 51.8 usec per loop</pre>
<p>We can also use <code>timeit</code> to see how PyPy stacks up again—but we’re in for a bit of a surprise:</p>
<pre data-type="programlisting">$ <code><strong>pypy3 -m timeit -n 1000 -r 50 "[x ** 2 for x in range(1000)]"</strong></code>
WARNING: timeit is a very unreliable tool. use pyperf or something 
else for real measurements
pypy3 -m pip install pyperf
pypy3 -m pyperf timeit -n '1000' -r '50' '[x ** 2 for x in range(1000)]'
------------------------------------------------------------
1000 loops, average of 50: 1.54 +- 0.568 usec per loop (using standard deviation)</pre>
<p>As you can see, PyPy has customized command-line mode in its version of <code>timeit</code> to both emit a subjective redirect to an alternative timer, as well as modify the result display to show averages instead of minimums. These are both opinionated mods made since this book’s prior edition, though perhaps understandable for a tool so focused on (and sensitive to) benchmark results. See the web for more on the suggested <em>pyperf</em>; it’s not part of Python’s standard library and requires a separate install, but may offer more advanced timing options that may or <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="command-line mode" data-startref="tmtmmld" id="id3345"></a>may not apply to your goals.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Handling multiline statements"><div class="sect3" id="handling_multiline_statements">
<h3>Handling multiline statements</h3>
<p>Happily, <code>timeit</code>’s API mode is still opinion-free today. To time larger blocks <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="multiline statements" id="tmtmmtls"></a>of code in <em>API-call</em> mode, either load code from a file, use a triple-quoted block string, or use newlines and tabs or spaces to satisfy Python’s syntax. Because you pass Python string objects to a Python function in this mode, there are no shell considerations, though be careful to handle nested quotes with escapes or mixed quotes if needed. The following, for instance, times <a data-type="xref" href="ch13.html#while_and_for_loops">Chapter 13</a> loop alternatives in CPython 3.12; you can use the same pattern to time the file-line-reader alternatives in <a data-type="xref" href="ch14.html#iterations_and_comprehensions">Chapter 14</a>:</p>
<pre data-type="programlisting">$ <code><strong>python3</strong></code>
&gt;&gt;&gt; <code><strong>import timeit</strong></code>
&gt;&gt;&gt; <code><strong>min(timeit.repeat(number=100_000, repeat=5,
        stmt='L = [1, 2, 3, 4, 5]\nfor i in range(len(L)): L[i] += 1'))</strong></code>
0.028153221122920513

&gt;&gt;&gt; <code><strong>min(timeit.repeat(number=100_000, repeat=5,
        stmt='L = [1, 2, 3, 4, 5]\ni=0\nwhile i &lt; len(L):\n\tL[i] += 1\n\ti += 1'))</strong></code>
0.03337613819167018

&gt;&gt;&gt; <code><strong>min(timeit.repeat(number=100_000, repeat=5,
        stmt='L = [1, 2, 3, 4, 5]\nM = [x + 1 for x in L]'))</strong></code>
0.021507765166461468</pre>
<p>To run multiline statements like these in <em>command-line</em> mode, appease your shell by passing each statement line as a separate argument, with whitespace for indentation—<code>timeit</code> concatenates all the lines together with a newline character between them, and later re-indents for its own statement-nesting purposes. Leading spaces may work better for indentation than tabs in this mode due to shell variability, and be sure to quote the code arguments if required by your shell (the first of the following was line-split here to fit, but must be <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="multiline statements" data-startref="tmtmmtls" id="id3346"></a>input on a single line in some shells):</p>
<pre data-type="programlisting">$ <code><strong>python3 -m timeit -n 100000 -r 5 "L = [1,2,3,4,5]" "i=0" "while i &lt; len(L):"</strong></code>
<code> <strong>"    L[i] += 1" "    i += 1"</strong></code>
100000 loops, best of 5: 332 nsec per loop

$ <code><strong>python3 -m timeit -n 100000 -r 5 "L = [1,2,3,4,5]" "M = [x + 1 for x in L]"</strong></code>
100000 loops, best of 5: 218 nsec per loop</pre>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Other timeit usage modes"><div class="sect3" id="other_timeit_usage_modes">
<h3>Other timeit usage modes</h3>
<p>The <code>timeit</code> module also <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="setup code" id="id3347"></a>allows you to provide <em>setup</em> code that is run in the main statement’s scope, but whose time is not charged to the main statement’s total—useful for initialization code you wish to exclude from total time, such as imports of required modules and builds of test data. Because they’re run in the same scope, any names created by setup code are available to the main test statement; names defined in the interactive shell generally are not.</p>
<p>To specify setup code, use a <code>–s</code> in command-line mode (or many of these for multiline setups) and a <code>setup</code> argument string in API-call mode. This can focus tests more sharply, as in the following, whose second command splits list initialization off to a setup statement to time just iteration in command-line mode. As a general rule of thumb, though, the more code you include in a test statement, the more applicable its results will generally be to realistic code:</p>
<pre data-type="programlisting">$ <code><strong>python3 -m timeit -n 100000 -r 5 "L = [1,2,3,4,5]" "M = [x + 1 for x in L]"</strong></code>
100000 loops, best of 5: 211 nsec per loop

$ <code><strong>python3 -m timeit -n 100000 -r 5 -s "L = [1,2,3,4,5]" "M = [x + 1 for x in L]"</strong></code>
100000 loops, best of 5: 175 nsec per loop</pre>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Timing sort speed"><div class="sect3" id="timing_sort_speed">
<h3>Timing sort speed</h3>
<p>To demo setup code in API-call mode, the <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="sort speed" id="tmtmmssp"></a>interaction that follows times a sort-based option in <a data-type="xref" href="ch18.html#arguments">Chapter 18</a>’s minimum-value example. To avoid page flipping, here’s the function it times, in the module <em>mins.py</em> (<a data-type="xref" href="ch18.html#example_oneeight_twodot_minsdotpy">Example 18-2</a>):</p>
<pre data-type="programlisting">def min4(*args):
    return sorted(args)[0]</pre>
<p>And here are the results—proving indirectly that sequences <em>sort much faster</em> when they are ordered than they do with randomly ordered contents (to see for yourself, run this in <a data-type="xref" href="ch18.html#arguments">Chapter 18</a>’s code folder):</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>from timeit import repeat</strong></code>                   <code><em># Standard-library module</em></code>

&gt;&gt;&gt; <code><strong>min(repeat(number=1000, repeat=5,</strong> </code>          <code><em># Sort an ordered list in min4</em></code>
<code> <strong>       setup='from mins import min4\n'</strong></code>         <code><em># Adjacent strings concatenated</em></code>
              <code><strong>'vals=list(range(1000))',</strong></code>         <code><em># Code within () spans lines</em></code>
<code> <strong>       stmt= 'min4(*vals)'))</strong></code>                   <code><em># First import prints output</em></code>
0.011066518723964691

&gt;&gt;&gt; <code><strong>min(repeat(number=1000, repeat=5,</strong> </code>          <code><em># Sort a randomly ordered list
</em> <strong>       setup='from mins import min4\n'
              'import random\n'</strong></code>
              <code><strong>'vals=[random.random() for i in range(1000)]',
        stmt= 'min4(*vals)'))</strong></code>
0.068130933213979<strong></strong></pre>
<p>See Python’s manuals for more on the <code>random</code> module used here and in earlier chapters, as well as more on <code>timeit</code>. Not shown here, <code>timeit</code> also lets you ask for just total time, time callable objects instead of strings, use a class-based API, and leverage additional command-line switches and API-call arguments we don’t have space to cover. Instead, the next <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="sort speed" data-startref="tmtmmssp" id="id3348"></a>section codes a <code>timeit</code> utility that goes beyond manual command lines and REPL calls.</p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Automating timeit Benchmarking"><div class="sect2" id="automating_timeit_benchmarking">
<h2>Automating timeit Benchmarking</h2>
<p>Rather than going into more <code>timeit</code> details, let’s study a program that deploys it to <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" id="id3349"></a>time both coding alternatives and Python versions. This will let us easily define a set of tests to time in a separate file, and will allow us collect data from multiple Pythons, both individually and grouped (though grouped mode comes with limits today, as you’ll see).</p>
<section data-type="sect3" data-pdf-bookmark="Benchmark module "><div class="sect3" id="benchmark_module">
<h3>Benchmark module </h3>
<p>To get started, the module file in <a data-type="xref" href="#example_twoone_eightdot_pybenchdotpy">Example 21-8</a>, <em>pybench.py</em>, is set up to time <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="benchmark module" id="tmbtbm"></a>a sequence of statements coded in scripts that import and use it, with either the Python running its code or all Python versions named in a list. It uses some application-level tools described ahead. Because it mostly applies ideas we’ve already explored and is amply documented, though, it’s listed as mostly self-study material, and an exercise in reading Python code.</p>
<div data-type="example" id="example_twoone_eightdot_pybenchdotpy">
<h5><span class="label">Example 21-8. </span>pybench.py</h5>
<pre data-type="programlisting">r"""
Time the speed of one or more Pythons on multiple code-string 
benchmarks with timeit.  This is a function, to allow timed tests
to vary.  It times all code strings in a passed list, in either:

1) The Python running this script, by timeit API calls
2) Multiple Pythons whose paths are passed in a list, by reading
   the output of timeit command lines run by os.popen that use 
   Python's -m switch to find timeit on the module search path

In command-line mode (2) only, this replaces all " in timed code
with ', to avoid clashes with argument quoting; splits multiline 
statements into one quoted argument per line so all will be run;
and replaces all \t in indentation with 4 spaces for uniformity.

Caveats: 
- Command-line mode (only) uses naive quoting and MAY FAIL if code
  embeds and requires double quotes; quoted code is incompatible 
  with the host shell; or command length exceeds shell limits.
- PyPy is largely unusable in command-line mode (2) today, as its
  modified timeit output in this mode is jarring in the report.
- This does not (yet?) support a setup statement in any mode: the
  time of all code in the test stmt is charged to its total time.
  
As fallbacks on fails, use either this module's API-call mode to 
test one Python at a time, or the homegrown timer.py module.
"""

import sys, os, time, timeit
defnum, defrep= 1000, 5    <em># May vary per stmt</em>

def show_context(): 
    """
    Show run's context using an arguably gratuitous f-string
    that fails on 3.10 PyPy without "..." for nested ' quotes.
    """
    print(f"Python {'.'.join(str(x) for x in sys.version_info[:3])}"
          f' on {sys.platform}'
          f" at {time.strftime('%b-%d-%Y, %H:%M:%S')}")

def runner(stmts, pythons=None, tracecmd=False):
    """
    Main logic: run tests per input lists which determine usage modes.
    stmts:   [(number?, repeat?, stmt-string)]
    pythons: None=host python only, or [python-executable-paths]
    """
    show_context()
    for (number, repeat, stmt) in stmts:
        number = number or defnum
        repeat = repeat or defrep    <em># 0=default</em>

        if not pythons:
            <em># Run stmt on this python: API call</em>
            <em># No need to split lines or quote here</em>
            best = min(timeit.repeat(stmt=stmt, number=number, repeat=repeat))
            print(f'{best:.4f}  {stmt[:70]!r}')

        else:
            <em># Run stmt on all pythons: command line</em>
            <em># Split lines into quoted arguments</em>
            print('-' * 80)
            print(repr(stmt))                                         <em># show quotes</em>
            for python in pythons:
                stmt  = stmt.replace('"', "'")                        <em># all " =&gt; '</em>
                stmt  = stmt.replace('\t', ' ' * 4)                   <em># tab =&gt; ____</em>
                lines = stmt.split('\n')                              <em># line =&gt; arg</em>
                args  = ' '.join(f'"{line}"' for line in lines)       <em># arg =&gt; "arg"</em>

                oscmd = f'{python} -m timeit -n {number} -r {repeat} {args}'
                print(oscmd if tracecmd else python)
                print('\t' + os.popen(oscmd).read().rstrip())</pre>
</div>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Benchmark script"><div class="sect3" id="benchmark_script">
<h3>Benchmark script</h3>
<p>This preceding file is really only half the <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="benchmark module" data-startref="tmbtbm" id="id3350"></a><a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="benchmark script" id="tmbscpt"></a>picture. Testing scripts use this module’s function, passing in concrete though variable lists of statements and Pythons to be tested, as appropriate for the usage mode desired. For example, the script in <a data-type="xref" href="#example_twoone_ninedot_pybench_testsdot">Example 21-9</a>, <em>pybench_tests.py</em>, tests a handful of statements and Pythons by importing and using <a data-type="xref" href="#example_twoone_eightdot_pybenchdotpy">Example 21-8</a>, and allows command-line arguments to determine part of its operation: <code>–a</code> tests all listed Pythons instead of just one, and an added <code>–t</code> traces constructed command lines in full so you can see how quotes, multiline statements, and tabs are handled per <code>timeit</code>’s command-line formats shown earlier (see both files’ docstrings for more details).</p>
<div data-type="example" id="example_twoone_ninedot_pybench_testsdot">
<h5><span class="label">Example 21-9. </span>pybench_tests.py</h5>
<pre data-type="programlisting">"""
Run pybench.py to time one or more Pythons on multiple code strings.
Use command-line arguments (which appear in sys.argv) to select modes:

&lt;python&gt; pybench_tests.py
    times just the hosting Python on all code listed in stmts below
python3 pybench_tests.py -a
    times all stmts in all pythons whose paths are listed below 
python3 pybench_tests.py -a -t
    same as -a, but also traces command lines in full

Edit stms below to change tested code, and edit pythons below to give 
paths of Python executables to be tested in -a mode.  To find a Python's 
path, start its REPL, run "import sys", and inspect "sys.executable".
"""

import pybench, sys

pythons = [
    '/Library/Frameworks/Python.framework/Versions/3.12/bin/python3',
    '/Users/me/Downloads/pypy3.10-v7.3.16-macos_x86_64/bin/pypy3',
]

stmts = [
<em># Iterations</em>
    (0, 0, '[x ** 2 for x in range(1000)]'),                        <code><em># (num,rpt,stmt)
</em></code>    (0, 0, 'res=[]\nfor x in range(1000): res.append(x ** 2)'),    <code> <em># \n=multistmt</em></code>
    (0, 0, 'list(map(lambda x: x ** 2, range(1000)))'),             <code><em># \n\t=indent</em></code>
    (0, 0, 'list(x ** 2 for x in range(1000))'),
<em># String ops</em>
    (0, 0, "s = 'hack' * 2500\nx = [s[i] for i in range(10_000)]"),
    (0, 0, "s = '?'\nfor i in range(10_000): s += '?'"),            <code><em># A PyPy loss!</em></code>
]

tracecmd = '-t' in sys.argv                           <code><em># -t: trace command lines?</em></code>
pythons  = pythons if '-a' in sys.argv else None      <code><em># -a: all in list, else one?</em></code>
pybench.runner(stmts, pythons, tracecmd)              <code><em># Time pythons on all stmts</em></code></pre>
</div>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Timing individual Pythons"><div class="sect3" id="timing_individual_pythons">
<h3>Timing individual Pythons</h3>
<p>The following is the preceding script’s output <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="benchmark script" data-startref="tmbscpt" id="id3351"></a><a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="individual Pythons" id="tmbscivp"></a>when run to test a <em>specific Python</em>—the one running the script. This mode uses direct <code>timeit</code> API calls, not command lines, with total time listed in the left column, the statement tested quoted on the right, and a context line at the top courtesy of Python’s <code>sys</code> and <code>time</code> modules (see its manuals for more info). These two runs again use CPython 3.12 and PyPy 7.3 (i.e., 3.10), respectively, on the same host:</p>
<pre data-type="programlisting">$ <code><strong>python3 pybench_tests.py</strong></code>
Python 3.12.2 on darwin at Jun-27-2024, 15:21:02
0.0533  '[x ** 2 for x in range(1000)]'
0.0605  'res=[]\nfor x in range(1000): res.append(x ** 2)'
0.0804  'list(map(lambda x: x ** 2, range(1000)))'
0.0759  'list(x ** 2 for x in range(1000))'
0.4042  "s = 'hack' * 2500\nx = [s[i] for i in range(10_000)]"
0.8061  "s = '?'\nfor i in range(10_000): s += '?'"

$ <code><strong>pypy3 pybench_tests.py</strong></code>
Python 3.10.14 on darwin at Jun-27-2024, 15:22:14
0.0020  '[x ** 2 for x in range(1000)]'
0.0040  'res=[]\nfor x in range(1000): res.append(x ** 2)'
0.0030  'list(map(lambda x: x ** 2, range(1000)))'
0.0077  'list(x ** 2 for x in range(1000))'
0.0529  "s = 'hack' * 2500\nx = [s[i] for i in range(10_000)]"
1.2942  "s = '?'\nfor i in range(10_000): s += '?'"</pre>
<p>Drawing conclusions from this is left as a suggested exercise, but notice that PyPy actually <em>loses</em> to <span class="keep-together">CPython</span> on the very last test run. Again, performance can vary per code, and absolutes <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="individual Pythons" data-startref="tmbscivp" id="id3352"></a>in benchmarking are perilous at best.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Timing multiple Pythons"><div class="sect3" id="timing_multiple_pythons">
<h3>Timing multiple Pythons</h3>
<p>As noted, this script can also test <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="multiple Pythons" id="id3353"></a>multiple Pythons for each statement string, by adding a <code>-a</code> to the command line. In this mode the script itself is run by CPython 3.12, which launches shell command lines that start other Pythons to run the <code>timeit</code> module on the statement strings. To make this work, this mode must split, format, and quote multiline statements for use in command lines according to both <code>timeit</code> expectations and shell requirements.</p>
<p>This mode also relies on the <code>-m</code> Python command-line flag to locate <code>timeit</code> on the module search path and run it as a script, as well as the <code>os.popen</code> and <code>sys.argv</code> standard-library tools to run a shell command and inspect command-line arguments, respectively. Add a <code>-t</code> to trace commands run, and see Python manuals and other resources for more on these tools; <code>os.popen</code> is also mentioned briefly in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.html#how_you_run_programs">3</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09.html#tuplescomma_filescomma_and_everything_e">9</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch13.html#while_and_for_loops">13</a>. Here is this mode’s result:</p>
<pre data-type="programlisting">$ <code><strong>python3 pybench_tests.py -a</strong></code>
Python 3.12.2 on darwin at Jun-27-2024, 16:12:39
--------------------------------------------------------------------------------
'[x ** 2 for x in range(1000)]'
/Library/Frameworks/Python.framework/Versions/3.12/bin/python3
    1000 loops, best of 5: 52.7 usec per loop
/Users/me/Downloads/pypy3.10-v7.3.16-macos_x86_64/bin/pypy3
    WARNING: timeit is a very unreliable tool. use pyperf or something 
    else for real measurements
pypy3 -m pip install pyperf
pypy3 -m pyperf timeit -n '1000' -r '5' '[x ** 2 for x in range(1000)]'
------------------------------------------------------------
1000 loops, average of 5: 2.66 +- 1.55 usec per loop (using standard deviation)
…<code><em>more output clipped</em></code>…</pre>
<p>Regrettably, this all-Pythons mode is nearly unusable today: the opinionated inserts and mods made to <code>timeit</code> by PyPy render its command-line output very different from the norm, and very difficult to read or list here. Moreover, there’s no way to disable these (short of dropping CPython’s <em>timeit.py</em> into PyPy’s library folder, which seems too much for this demo to ask). Hence, while this script’s <code>-a</code> mode still works in this edition, it may be best used to time a set of Pythons that do not subjectively mod the behavior of a widely used standard-library module like <code>timeit</code>.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Timing set and dictionary iterations"><div class="sect3" id="timing_set_and_dictionary_iterations">
<h3>Timing set and dictionary iterations</h3>
<p>The good news is that <em>single-Python</em> mode <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="sets" id="tmmbmk"></a><a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="dictionaries" id="mmbkud"></a>still allows us to easily script a set of benchmarks—even on PyPy. The script in <a data-type="xref" href="#example_twoone_onezerodot_pybench_tests">Example 21-10</a>, for instance, uses the driver module in <a data-type="xref" href="#example_twoone_eightdot_pybenchdotpy">Example 21-8</a> to see how sets and dictionaries fare.</p>
<div data-type="example" class="pagebreak-before" id="example_twoone_onezerodot_pybench_tests">
<h5 class="less_space"><span class="label">Example 21-10. </span>pybench_tests2.py</h5>
<pre data-type="programlisting">import pybench<strong></strong>

stmts = [
<em># Sets</em>
    (0, 0, '{x ** 2 for x in range(1000)}'),
    (0, 0, 'set(x ** 2 for x in range(1000))'),
    (0, 0, 's=set()\nfor x in range(1000): s.add(x ** 2)'),
<em># Dicts</em>
    (0, 0, '{x: x ** 2 for x in range(1000)}'),
    (0, 0, 'dict((x, x ** 2) for x in range(1000))'),
    (0, 0, 'd={}\nfor x in range(1000): d[x] = x ** 2'),
]

pybench.runner(stmts, None, False)    <em># No -a mode in this script</em></pre>
</div>
<p>As suggested in the preceding chapter, passing a generator to a type name is indeed substantially slower than other construction schemes—as this script’s output on both CPython 3.12 and PyPy 7.3 (3.10) finally proves:</p>
<pre data-type="programlisting">$ <code><strong>python3 pybench_tests2.py</strong></code>
Python 3.12.2 on darwin at Jun-27-2024, 16:20:19
0.0746  '{x ** 2 for x in range(1000)}'
0.0947  'set(x ** 2 for x in range(1000))'
0.0834  's=set()\nfor x in range(1000): s.add(x ** 2)'
0.0745  '{x: x ** 2 for x in range(1000)}'
0.1174  'dict((x, x ** 2) for x in range(1000))'
0.0754  'd={}\nfor x in range(1000): d[x] = x ** 2'

$ <code><strong>pypy3 pybench_tests2.py</strong></code> 
Python 3.10.14 on darwin at Jun-27-2024, 16:22:18
0.0191  '{x ** 2 for x in range(1000)}'
0.0222  'set(x ** 2 for x in range(1000))'
0.0186  's=set()\nfor x in range(1000): s.add(x ** 2)'
0.0188  '{x: x ** 2 for x in range(1000)}'
0.0398  'dict((x, x ** 2) for x in range(1000))'
0.0185  'd={}\nfor x in range(1000): d[x] = x ** 2'</pre>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Conclusion: Comparing tools"><div class="sect3" id="conclusion_comparing_tools">
<h3>Conclusion: Comparing tools</h3>
<p>If you have time, check <a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="sets" data-startref="tmmbmk" id="id3354"></a><a contenteditable="false" data-type="indexterm" data-primary="timeit module" data-secondary="benchmarking automation" data-tertiary="dictionaries" data-startref="mmbkud" id="id3355"></a>out <em>pybench_tests3.py</em> in the book example’s package (omitted here for space) for another test that verifies that this section’s <code>timeit</code> tools turn in results similar to the earlier <em>timer.py</em> homegrown tools. Its findings generally jive with those in <a data-type="xref" href="#iteration_results">“Iteration Results”</a>, though they arrive at them by very different means:</p>
<pre data-type="programlisting">$ <code><strong>python3 pybench_tests3.py</strong></code> 
Python 3.12.2 on darwin at Jun-27-2024, 16:26:44
0.2766  "res=[]\nfor x in 'hack' * 2500: res.append(ord(x))"
0.2173  "[ord(x) for x in 'hack' * 2500]"
0.1430  "list(map(ord, 'hack' * 2500))"
0.4172  "list(ord(x) for x in 'hack' * 2500)"</pre>
<p>For more fidelity, study this chapter’s code and run more tests on your own. Benchmarks can be great sport, but we’ll have to leave further excursions as suggested exercises. Here, it’s time to wrap up this chapter and part, so we can move on to learn more about the modules we’ve been using informally since <a data-type="xref" href="ch16.html#function_basics">Chapter 16</a>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p><em>Cross-platform results</em>: As a bonus, folder <code>_benchmark-platform-results</code> in the book’s examples package collects CPython’s results for this chapter’s <em>timer</em> and <em>pybench</em> tests on multiple platforms—macOS, Windows, Android, and Linux. Due to Python and host differences, not all its results are directly comparable, but they are relatively similar. Surprisingly, an Android foldable phone beats all the PCs, though these tests are CPU bound, and operations <a contenteditable="false" data-type="indexterm" data-primary="benchmarking" data-secondary="timeit module" data-startref="bchktmdl" id="id3356"></a>like file access may fare differently. Caveat: these results <em>will</em> change; retest with your Pythons and devices for current data.</p>
</div>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Function Gotchas"><div class="sect1" id="function_gotchas">
<h1>Function Gotchas</h1>
<p>Now that we’ve reached the end of the function story, let’s review some common pitfalls. Functions have some jagged edges that you might not expect. They’re all relatively obscure, and a few have started to fall away from the language completely in recent releases, but most have been known to trip up new users.</p>
<section data-type="sect2" data-pdf-bookmark="Local Names Are Detected Statically"><div class="sect2" id="local_names_are_detected_statically">
<h2>Local Names Are Detected Statically</h2>
<p>As you’ve learned, Python classifies names <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="names, locals" id="fctnnlc"></a>assigned in a function as <em>locals</em> by default; they live in the function’s scope and exist only while the function is running. What you may not realize is that Python detects locals statically, when it compiles the <code>def</code>’s code, rather than by noticing assignments as they happen at runtime. This leads to one of the most common oddities posted on the Python newsgroup by beginners.</p>
<p>Normally, a name that isn’t assigned in a function is looked up in the enclosing module:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>X = 99
</strong></code>
&gt;&gt;&gt; <code><strong>def selector():</strong></code>       <code><em># X used but not assigned</em></code>
        <code><strong>print(X)</strong></code>          <code><em># X found in global scope</em></code>

&gt;&gt;&gt; <code><strong>selector()</strong></code>
99</pre>
<p>Here, the <code>X</code> in the function resolves to the <code>X</code> in the module. But watch what happens if you add an assignment to <code>X</code> after the reference:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def selector():
        print(X)</strong></code>          <code><em># Does not yet exist!</em></code>
        <code><strong>X = 88</strong></code>            <code><em># X classified as a local name (everywhere)</em></code>
                          <code><em># Can also happen for "import X", "def X"...</em></code>
&gt;&gt;&gt; <code><strong>selector()</strong></code>
UnboundLocalError: cannot access local variable 'X' where it is not associated with a value</pre>
<p>You get the name-usage error shown here, but the reason is subtle. Python reads and compiles this code when it’s typed interactively or imported from a module. While compiling, Python sees the assignment to <code>X</code> and decides that <code>X</code> will be a local name everywhere in the function. But when the function is actually run, because the assignment hasn’t yet happened when the <code>print</code> executes, Python says you’re using an undefined name. According to its name rules, it should say this; the local <code>X</code> is used before being assigned. In fact, any assignment in a function body makes a name local. Imports, <code>=</code>, nested <code>def</code>s, nested classes, and so on are all susceptible to this behavior.</p>
<p>The problem occurs because assigned names are treated as locals everywhere in a function, not just after the statements where they’re assigned. Really, the previous example is ambiguous: was the <span class="keep-together">intention</span> to print the global <code>X</code> and create a local <code>X</code>, or is this a real programming error? Because Python treats <code>X</code> as a local everywhere, it’s seen as an error; if you mean to print the global <code>X</code>, you need to declare it in a <code>global</code> statement:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def selector():
        global X</strong></code>                <code><em># Force X to be global (everywhere in function)</em></code>
        <code><strong>print(X)
        X = 88
</strong></code>
&gt;&gt;&gt; <code><strong>selector()</strong></code>
99</pre>
<p>Remember, though, that this means the assignment also changes the global <code>X</code>, not a local <code>X</code>. Within a function, you can’t use both local and global versions of the same simple name. If you really meant to print the global and then set a local of the same name, you’d need to import the enclosing module and use module attribute notation to get to the global version:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>X = 99
</strong></code>&gt;&gt;&gt; <code><strong>def selector():
        import __main__</strong></code>         <code><em># Import enclosing module</em></code>
        <code><strong>print(__main__.X)</strong></code>       <code><em># Qualify to get to global version of name</em></code>
        <code><strong>X = 88</strong></code>                  <code><em># Unqualified X classified as local</em></code>
        <code><strong>print(X)</strong></code>                <code><em># Prints local version of name</em></code>

&gt;&gt;&gt; <code><strong>selector()</strong></code>
99
88</pre>
<p>Qualification (the <code>.X</code> part) fetches a value from a namespace object. The interactive namespace is a module called <code>__main__</code>, so <code>__main__.X</code> reaches the global version of <code>X</code>. If that isn’t clear, review <span class="keep-together"><a data-type="xref" href="ch17.html#scopes">Chapter 17</a></span>.</p>
<p>In recent versions, Python has <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="names, locals" data-startref="fctnnlc" id="id3357"></a>improved on this story somewhat by issuing for this case the more specific “unbound local” error message shown in the example listing (it used to simply raise a generic name error); this gotcha is still present in general, though.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Defaults and Mutable Objects"><div class="sect2" id="defaults_and_mutable_objects">
<h2>Defaults and Mutable Objects</h2>
<p>As noted briefly in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch17.html#scopes">17</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch18.html#arguments">18</a>, mutable values for default arguments can retain state between <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="defaults" id="fctndfl"></a><a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="objects, mutable" id="fcbjtb"></a><a contenteditable="false" data-type="indexterm" data-primary="mutable objects" data-secondary="functions" id="mtbjf"></a><a contenteditable="false" data-type="indexterm" data-primary="objects" data-secondary="mutable" data-tertiary="functions" id="bjmtcut"></a>calls, though this is often unexpected. In general, default argument values are evaluated and saved <em>once</em> when a <code>def</code> statement is run, not each time the resulting function is later called. Internally, Python saves one object per default argument, attached to the function itself.</p>
<p>That’s usually what you want—because defaults are evaluated at <code>def</code> time, they let you save values from the enclosing scope, if needed (functions defined within loops by factories may even depend on this behavior—see ahead). But because a default retains an object between calls, you have to be careful about changing mutable defaults. For instance, the following function uses an empty list as a default value, and then changes it in place each time the function is called:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def saver(x=[]):</strong></code>               <code><em># Saves away a list object</em></code>
        <code><strong>x.append(1)</strong></code>                <code><em># Changes same object each time!</em></code>
        <code><strong>print(x)</strong></code>

&gt;&gt;&gt; <code><strong>saver([2])</strong></code>                     <code><em># Default not used</em></code>
[2, 1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>                        <code><em># Default used</em></code>
[1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>                        <code><em># Grows on each call!</em></code>
[1, 1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>
[1, 1, 1]</pre>
<p>Some see this behavior as a feature—because mutable default arguments retain their state between function calls, they can serve some of the same roles as “static” local function variables in the C language. In a sense, they work much like global variables, but their names are local to the functions and so will not clash with names elsewhere in a program.</p>
<p>To other observers, though, this seems like a gotcha—especially the first time they run into it. There are better ways to retain state between calls in Python (e.g., using the nested scope closures and function attributes we met in this part, and the classes we will study in <a data-type="xref" href="part06.html#classes_and_oop">Part VI</a>).</p>
<p>Moreover, mutable defaults can be overridden by real values, and are tricky to remember (and to understand at all). They depend upon the timing of default object construction. In the prior example, there is just one list object for the default value—the one created when the <code>def</code> is executed. You don’t get a new list every time the function is called, so the list grows with each new append; it is not reset to empty each time.</p>
<p>If that’s not the behavior you want, simply make a copy of the default at the start of the function body, or move the default value expression into the function body. As long as the value resides in code that’s actually executed each time the function is <em>called</em>, you’ll get a new object each time through:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def saver(x=None):
        if x is None:</strong></code>             <code><em># No argument passed?</em></code>
            <code><strong>x = []</strong></code>                <code><em># Run code to make a new list each time
</em></code>        <code><strong>x.append(1)</strong></code>               <code><em># Changes new list object</em></code>
        <code><strong>print(x)
</strong></code>
&gt;&gt;&gt; <code><strong>saver([2])</strong></code>
[2, 1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>                       <code><em># Doesn't grow here</em></code>
[1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>
[1]</pre>
<p>By the way, the <code>if</code> statement in this example could <em>almost</em> be replaced by the assignment <code>x = x or []</code>, which takes advantage of the fact that Python’s <code>or</code> returns one of its operand objects: if no argument was passed, <code>x</code> would default to <code>None</code>, so the <code>or</code> would return the new empty list on the right.</p>
<p>However, this isn’t exactly the same. If an empty list were passed in, the <code>or</code> expression would cause the function to extend and return a newly created list, rather than extending and returning the passed-in list like the <code>if</code> version. (The expression becomes <code>[] or []</code>, which evaluates to the new empty list on the right; see <a data-type="xref" href="ch12.html#if_and_match_selections">Chapter 12</a>’s “Truth Values Revisited” if you don’t recall why.) Real program requirements may call for either behavior.</p>
<p>Today, another way to achieve the value retention effect of mutable defaults in a possibly less confusing way is to use the <em>function attributes</em> we discussed in <a data-type="xref" href="ch19.html#function_odds_and_ends">Chapter 19</a>:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def saver():
        saver.x.append(1)
        print(saver.x)

</strong></code>&gt;&gt;&gt; <code><strong>saver.x = []</strong></code>
&gt;&gt;&gt; <code><strong>saver()</strong></code>
[1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>
[1, 1]
&gt;&gt;&gt; <code><strong>saver()</strong></code>
[1, 1, 1]</pre>
<p>The function name is global to the function itself, but it need not be declared because it isn’t changed directly within the function. This isn’t used in exactly the same way, but when coded <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="defaults" data-startref="fctndfl" id="id3358"></a><a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="objects, mutable" data-startref="fcbjtb" id="id3359"></a><a contenteditable="false" data-type="indexterm" data-primary="mutable objects" data-secondary="functions" data-startref="mtbjf" id="id3360"></a><a contenteditable="false" data-type="indexterm" data-primary="objects" data-secondary="mutable" data-tertiary="functions" data-startref="bjmtcut" id="id3361"></a>like this, the attachment of an object to the function is much more explicit (and arguably less magical).</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Functions Without returns"><div class="sect2" id="functions_without_returns">
<h2>Functions Without returns</h2>
<p>In Python functions, <code>return</code> (and <code>yield</code>) statements are optional. When a function <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="returns" id="id3362"></a><a contenteditable="false" data-type="indexterm" data-primary="returns, none" id="id3363"></a>doesn’t return a value explicitly, the function exits when control falls off the end of the function body. Technically, all functions return a value; if you don’t provide a <code>return</code> statement, your function returns the <code>None</code> object automatically:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>def proc(x):
        print(x)</strong></code>                 <code><em># No return is a None return</em></code>

&gt;&gt;&gt; <code><strong>x = proc('testing 123...')</strong></code>
testing 123...
&gt;&gt;&gt; <code><strong>print(x)</strong></code>
None</pre>
<p>Functions such as this without a <code>return</code> are Python’s equivalent of what are called “procedures” in some languages. They’re usually invoked as statements, and the <code>None</code> results are ignored, as they do their business without computing a useful result.</p>
<p>This is worth remembering, because Python won’t tell you if you try to use the result of a function that doesn’t return one. As we noted in <a data-type="xref" href="ch11.html#assignmentscomma_expressionscomma_and_p">Chapter 11</a>, for instance, assigning the result of a list <code>append</code> method won’t raise an error, but you’ll get back <code>None</code>, not the modified list:</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>list = [1, 2, 3]</strong></code>
&gt;&gt;&gt; <code><strong>list = list.append(4)</strong></code>        <code><em># append is a "procedure"</em></code>
&gt;&gt;&gt; <code><strong>print(list)</strong></code>                  <code><em># append changes list in place</em></code>
None</pre>
<p><a data-type="xref" href="ch15.html#common_coding_gotchas">“Common Coding Gotchas”</a> discusses this more broadly. In general, any functions that do their business as a side effect are usually designed to be run as statements, not <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="returns" data-startref="fctrtrnn" id="id3364"></a>expressions.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Miscellaneous Function Gotchas"><div class="sect2" id="miscellaneous_function_gotchas">
<h2>Miscellaneous Function Gotchas</h2>
<p>Here are two additional function-related gotchas—mostly reviews, but common enough to reiterate.</p>
<section data-type="sect3" data-pdf-bookmark="Enclosing scopes and loop variables"><div class="sect3" id="enclosing_scopes_and_loop_variables">
<h3>Enclosing scopes and loop variables</h3>
<p>We met this gotcha in <a data-type="xref" href="ch17.html#scopes">Chapter 17</a>’s discussion of enclosing function <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="scopes, enclosing" id="id3365"></a><a contenteditable="false" data-type="indexterm" data-primary="scopes" data-secondary="enclosing" id="id3366"></a><a contenteditable="false" data-type="indexterm" data-primary="scopes" data-secondary="enclosing" data-tertiary="functions" id="id3367"></a><a contenteditable="false" data-type="indexterm" data-primary="enclosing scopes" data-secondary="functions" id="id3368"></a>scopes, but as a reminder: when coding factory functions (a.k.a. closures), be careful about relying on enclosing function scope lookup for var<a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="loop variables" id="id3369"></a><a contenteditable="false" data-type="indexterm" data-primary="loops" data-secondary="variables" id="id3370"></a><a contenteditable="false" data-type="indexterm" data-primary="variables" data-secondary="loops" id="id3371"></a>iables that are changed by enclosing loops. When a generated function is later called, all such references will remember the value of the <em>last</em> loop iteration in the enclosing function’s scope. In this case, you must use <em>defaults</em> to save loop variable values instead of relying on automatic lookup in enclosing scopes. See <a data-type="xref" href="ch17.html#loops_require_defaultscomma_not_scopes">“Loops Require Defaults, Not Scopes”</a> in <a data-type="xref" href="ch17.html#scopes">Chapter 17</a> for more details on this topic.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Hiding built-ins by assignment"><div class="sect3" id="hiding_built_ins_by_assignment">
<h3>Hiding built-ins by assignment</h3>
<p>Also in <a data-type="xref" href="ch17.html#scopes">Chapter 17</a>, we saw how it’s possible to reassign built-in names <a contenteditable="false" data-type="indexterm" data-primary="functions" data-secondary="built-in, handling by assignment" id="id3372"></a><a contenteditable="false" data-type="indexterm" data-primary="built-in functions" data-secondary="handling by assignment" id="id3373"></a>in a closer local or global scope; the reassignment effectively hides (“shadows”) and replaces that built-in’s name for the remainder of the scope where the assignment occurs. This means you won’t be able to use the original built-in value for the name. As long as you don’t need the built-in value of the name you’re assigning, this isn’t an issue—many names are built in, and they may be freely reused. However, if you reassign a built-in name your code relies on, you may have problems. So don’t do that, unless you really mean to. The good news is that the built-ins you commonly use will soon become second nature, and Python’s error trapping will alert you early in testing if your built-in name is not what you think it is.</p>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Chapter Summary"><div class="sect1" id="chapter_summary-id00032">
<h1>Chapter Summary</h1>
<p>This chapter rounded out our look at functions and built-in iteration tools with a larger case study that measured the performance of iteration alternatives and other tools we’ve met along the way, as well as one alternative Python implementation. We used both custom timer code as well as Python’s <code>timeit</code> with a helper to time code in a variety of modes. We also reviewed common function-related mistakes to help you avoid pitfalls.</p>
<p>This concludes the functions part of this book. The next part expands on what we already know about <em>modules</em>—files of tools that form the topmost organizational unit in Python programs, and the structure in which functions reside. After that, we will explore <em>classes</em>, which are largely packages of functions with special first arguments. As you’ll see, classes can implement objects that tap into the iteration protocol, just like the generators and iterables we used here. In fact, everything we have learned in this part of the book will apply when functions take the guise of class methods.</p>
<p>Before moving on to modules, though, be sure to work through this chapter’s quiz, as well as the exercises for this part of the book, to practice what you’ve learned about functions here.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Test Your Knowledge: Quiz"><div class="sect1" id="test_your_knowledge_quiz-id000163">
<h1>Test Your Knowledge: Quiz</h1>
<ol>
<li><p>What conclusions can you draw from this chapter about the relative speed of Python iteration tools?</p></li>
<li><p>What conclusions can you draw from this chapter about the relative speed of the Pythons timed?</p></li>
</ol>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Test Your Knowledge: Answers"><div class="sect1" id="test_your_knowledge_answers-id000162">
<h1>Test Your Knowledge: Answers</h1>
<ol>
<li><p>In CPython today, list comprehensions are often the quickest of the bunch; <code>map</code> beats list comprehensions in Python when all tools must call built-in functions; <code>for</code> loops tend to be slower than comprehensions; and generator functions and expressions are slower than all other options. Under PyPy, some of these findings differ; <code>map</code> often turns in a different relative performance, for example, and list comprehensions seem always quickest, perhaps due to function-level optimizations.</p>
<p><em>At least that’s the case today</em> on the Python versions tested, on the test machine used, and for the type of code timed—these results may vary if any of these three variables differ. Use the homegrown <code>timer</code> or standard library <code>timeit</code> to test your use cases for more relevant results. Also keep in mind that iteration is just one component of a program’s time: more code gives a more complete picture.</p></li>
<li><p>In general, PyPy 7.3 (implementing Python 3.10) is substantially faster than CPython 3.12. In some cases timed, PyPy was 5X–20X faster than CPython, though in isolated cases (e.g., some string operations), PyPy was slower than CPython, and PyPy’s use of a JIT can impact benchmark results.</p>
<p><em>At least that’s the case today</em> on the Python versions tested, on the test machine used, and for the type of code timed—these results may vary if any of these three variables differ. Use the homegrown <code>timer</code> or standard library <code>timeit</code> to test your use cases for more relevant results. This is especially true when timing Python implementations, which may be arbitrarily optimized in each new release—in fact, CPython may soon adopt a JIT like PyPy, which could invalidate results here. We also didn’t test any of the many other Python implementations; see <a data-type="xref" href="ch02.html#how_python_runs_programs">Chapter 2</a> for other options to time on your own.</p></li>
</ol>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Test Your Knowledge: Part IV Exercises"><div class="sect1" id="test_your_knowledge_part_iv_exercises">
<h1>Test Your Knowledge: Part IV Exercises</h1>
<p>In these exercises, you’re going to start coding more sophisticated programs. Be sure to check the solutions in <a data-type="xref" href="app02.html#part_ivcomma_functions_and_generators">“Part IV, Functions and Generators”</a> in <a data-type="xref" href="app02.html#appendix_b_solutions_to_end_of_part_exe">Appendix B</a>, and be sure to start writing your code in module files. You won’t want to retype these exercises in a REPL if you make a mistake.</p>
<ol>
<li><p><em>The basics</em>: At the Python interactive prompt, write a function named <code>echo</code> that prints its single argument to the screen and call it interactively, passing a variety of object types: string, integer, list, dictionary. Then, try calling it without passing any argument. What happens? What happens when you pass two arguments?</p></li>
<li><p><em>Arguments</em>: Write a function called <code>adder</code> in a Python module file named <em>adder1.py</em>. The function should accept two arguments and return the sum (or concatenation) of the two. Then, add code at the bottom of the file to call the <code>adder</code> function with a variety of object types (two strings, two lists, two floating points), and run this file as a script from the system command line. Do you have to print the call statement results to see results on your screen?</p></li>
<li><p><em>Arbitrary arguments</em>: Copy the file you wrote in the last exercise to <em>adder2.py</em>, generalize its <code>adder</code> function to compute the sum of an arbitrary number of arguments, and change the calls to pass more or fewer than two arguments. What type is the returned sum? (Hints: a slice such as <code>S[:0]</code> returns an empty sequence of the same type as <code>S</code>, and the <code>type</code> built-in function can test types; but see the manually coded <code>min</code> examples in <a data-type="xref" href="ch18.html#arguments">Chapter 18</a> for a simpler approach.) What happens if you pass in arguments of different types? What about passing in dictionaries?</p></li>
<li><p><em>Keywords</em>: In an <em>adder3.py</em>, change the <code>adder</code> function from exercise 2 to accept and sum/concatenate three arguments: <code>def adder(red, green, blue)</code>. Now, provide <em>default</em> values for each argument, and experiment with calling the function interactively or code tests in the file. Try passing one, two, three, and four arguments. Then, try passing <em>keyword</em> arguments. Does the call <code>adder(blue=1, red=2)</code> work? Why? Finally, copy and generalize the new <code>adder</code> to accept and sum/concatenate an <em>arbitrary</em> number of keyword arguments in an <em>adder4.py</em>. This is similar to what you did in exercise 3, but you’ll need to iterate over a dictionary, not a tuple. (Hint: the <code>dict.keys</code> method returns an iterable you can step through with a <code>for</code> or <code>while</code>, but be sure to wrap it in a <code>list</code> call to index it; <code>dict.values</code> may help here too.)</p></li>
<li><p><em>Dictionary tools</em>: Write a function called <code>copyDict(dict)</code> that copies its dictionary argument. It should return a new dictionary containing all the items in its argument. Use the dictionary <code>keys</code> method to iterate (or step over a dictionary’s keys without calling <code>keys</code>). Copying sequences is easy (<code>X[:]</code> makes a top-level copy); does this work for dictionaries, too? As explained in this exercise’s solution, because dictionaries come with similar tools, this and the next exercise are just coding exercises but still serve as representative functions.</p></li>
<li><p><em>Dictionary tools</em>: Write a function called <code>addDict(dict1, dict2)</code> that computes the union (i.e., merge) of two dictionaries. It should return a new dictionary containing all the items in both its arguments (which are assumed to be dictionaries). If the same key appears in both arguments, feel free to pick a value from either. Test your function by writing it in a file and running the file as a script. What happens if you pass lists instead of dictionaries? How could you generalize your function to handle this case, too? (Hint: see the <code>type</code> built-in function used earlier.) Does the order of the arguments passed in matter? Dictionary merge is also a built-in today (actually, several), but you’re trying to stretch yourself a bit by coding it manually.</p></li>
<li><p><em>More argument-matching examples</em>: First, define the following six functions (either interactively or in a module file that can be imported):</p>
<pre data-type="programlisting">def f1(a, b): print(a, b)            <code><em># Normal args</em></code>

def f2(a, *b): print(a, b)           <code><em># Positional collectors</em></code>

def f3(a, **b): print(a, b)          <code><em># Keyword collectors</em></code>

def f4(a, *b, **c): print(a, b, c)   <code><em># Mixed modes</em></code>

def f5(a, b=2, c=3): print(a, b, c)  <code><em># Defaults</em></code>

def f6(a, b=2, *c): print(a, b, c)  <code> <em># Defaults and positional collectors</em></code></pre>
<p>Now, test the following calls interactively, and try to explain each result; in some cases, you’ll probably need to fall back on the matching rules covered in <a data-type="xref" href="ch18.html#arguments">Chapter 18</a>. Do you think mixing matching modes is a good idea in general? Can you think of cases where it would be useful?</p>
<pre data-type="programlisting">&gt;&gt;&gt; <code><strong>f1(1, 2)</strong></code>
&gt;&gt;&gt; <code><strong>f1(b=2, a=1)</strong></code>

&gt;&gt;&gt; <code><strong>f2(1, 2, 3)</strong></code>
&gt;&gt;&gt; <code><strong>f3(1, x=2, y=3)
</strong></code>&gt;&gt;&gt; <code><strong>f4(1, 2, 3, **dict(x=2, y=3))</strong></code>

&gt;&gt;&gt; <code><strong>f5(1)</strong></code>
&gt;&gt;&gt; <code><strong>f5(1, 4)</strong></code>
&gt;&gt;&gt; <code><strong>f5(1, c=4)</strong></code>

&gt;&gt;&gt; <code><strong>f6(1)</strong></code>
&gt;&gt;&gt; <code><strong>f6(1, *[3, 4])</strong></code></pre></li>
<li><p><em>Primes revisited</em>: Recall the following code snippet from <a data-type="xref" href="ch13.html#while_and_for_loops">Chapter 13</a>, which simplistically determines whether a positive integer is prime:</p>
<pre data-type="programlisting">x = num // 2                              <code><em># For some num &gt; 1, start at half</em></code>
while x &gt; 1:
    if num % x == 0:                      <code><em># Remainder 0? Factor found</em></code>
        print(num, 'has factor', x)
        break                             <code><em># Exit now and skip else</em></code>
    x -= 1
else:                                     <code><em># Normal exit, when x reaches 1</em></code>
    print(num, 'is prime')</pre>
<p>Package this code as a reusable function in a module file (<code>num</code> should be a passed-in argument), and add some calls to the function at the bottom of your file to test. While you’re at it, experiment with replacing the first line’s <code>//</code> operator with <code>/</code> to see how <em>true</em> division breaks this code (refer back to <a data-type="xref" href="ch05.html#numbers_and_expressions">Chapter 5</a> if you need a reminder). What can you do about negatives, and the values <code>0</code> and <code>1</code>? How about speeding this up? Your outputs should look something like this:</p>
<pre data-type="programlisting">13 is prime
13.0 is prime
15 has factor 5
15.0 has factor 5.0</pre></li>
<li><p><em>Iterations and comprehensions</em>: Write code to build a new list containing the square roots of all the numbers in this list: <code>[2, 4, 9, 16, 25]</code>. Code this as a <code>for</code> loop first, then as a <code>map</code> call, then as a list comprehension, and finally as a generator expression. Use the <code>sqrt</code> function in the built-in <code>math</code> module to do the calculation (i.e., import <code>math</code> and say <code>math.sqrt(<em>X</em>)</code>). Of the four, which approach do you like best?</p></li>
<li><p><em>Timing tools</em>: In <a data-type="xref" href="ch05.html#numbers_and_expressions">Chapter 5</a>, we saw three ways to compute square roots: <code>math.sqrt(<em>X</em>)</code>, <code><em>X</em> ** .5</code>, and <code>pow(<em>X</em>, .5)</code>. If your programs run a lot of these, their relative performance might become important. To see which is quickest, use the <em>timer2.py</em> module (<a data-type="xref" href="#example_twoone_sevendot_timertwodotpy">Example 21-7</a>) we wrote in this chapter to time each of these three tools. Use its <code>bestoftotal</code> function to test. Which of the three square root tools seems to run fastest on your device and Python in general? Finally, how might you use <em>timer2.py</em> to interactively time the speed of dictionary comprehensions versus <code>for</code> loops? What about comprehensions with <code>if</code> clauses and nested <code>for</code> loops?</p></li>
<li><p><em>Recursive functions</em>: Write a simple recursion function named <code>countdown</code> that prints numbers as it counts down to zero. For example, a call <code>countdown(5)</code> will print: <code>5 4 3 2 1 stop</code>. There’s no obvious reason to code this with an explicit stack or queue, but what about a nonfunction approach? Would a generator make sense here?</p></li>
<li><p><em>Computing factorials</em>: Finally, a computer-science classic (but demonstrative nonetheless). We employed the notion of factorials in <a data-type="xref" href="ch20.html#comprehensions_and_generations">Chapter 20</a>’s coverage of permutations: <code>N!</code>, computed as <code>N*(N-1)*(N-2)*...1</code>. For instance, <code>6!</code> is <code>6*5*4*3*2*1</code>, or <code>720</code>. Code and time four functions that, for a call <code>fact(N)</code>, each return <code>N!</code>. Code these four functions (1) as a recursive countdown per <a data-type="xref" href="ch19.html#function_odds_and_ends">Chapter 19</a>; (2) using the functional <code>reduce</code> call per <a data-type="xref" href="ch19.html#function_odds_and_ends">Chapter 19</a>; (3) with a simple iterative counter loop per <a data-type="xref" href="ch13.html#while_and_for_loops">Chapter 13</a>; and (4) using the <code>math.factorial</code> library tool per <a data-type="xref" href="ch20.html#comprehensions_and_generations">Chapter 20</a>. Use this chapter’s <code>timeit</code> to time each of your functions. What conclusions can you draw from your results?</p></li>
</ol>
</div></section>
</div></section></div>
</div>
</body>
</html>