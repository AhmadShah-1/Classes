### Linear Regression
![[Pasted image 20250921165934.png]]

![[Pasted image 20250921170026.png]]

![[Pasted image 20250921174447.png]]

![[Pasted image 20250921174506.png]]
m is the number of points, so we are effectively taking the average of the points

![[Pasted image 20250928162243.png]]


![[Pasted image 20250921180921.png]]

![[Pasted image 20250921180930.png]]
 ![[Pasted image 20250921181652.png]]

![[Pasted image 20250921181833.png]]

![[Pasted image 20250921183113.png]]

## Gradient Descent:

![[Pasted image 20251005145049.png]]

![[Pasted image 20251005145412.png]]

![[Pasted image 20251005145530.png]]

![[Pasted image 20251005145547.png]]
Two ways to apply this
- Train everything one by one, updating each value (BGD)
- Group it and do it all in one update (SGD)

![[Pasted image 20251005145747.png]]


![[Pasted image 20251005152037.png]]

![[Pasted image 20251005152145.png]]

![[Pasted image 20251005152719.png]]

![[Pasted image 20251005153024.png]]

![[Pasted image 20251005153245.png]]

![[Pasted image 20251005153412.png]]

![[Pasted image 20251005154030.png]]

