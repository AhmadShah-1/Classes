

For Midterm:
answer each question with work on paper (will be similar to the quizzes)
3 hours to do it (30 minute to upload)
only calculations and concept questions (no coding questions)


# Bayesian Learning

I am very shaky about my understanding of this

![[Pasted image 20251115165753.png]]

![[Pasted image 20251115170000.png]]
![[Pasted image 20251115170127.png]]
![[Pasted image 20251115170137.png]]
![[Pasted image 20251115170145.png]]
![[Pasted image 20251115170152.png]]




![[Pasted image 20251115170551.png]]

![[Pasted image 20251115170618.png]]
![[Pasted image 20251115170656.png]]




![[Pasted image 20251115171135.png]]
MAP = Maximum A Posteriori
ML = Maximum Likelihood
![[Pasted image 20251115171029.png]]
![[Pasted image 20251115171107.png]]


![[Pasted image 20251115171203.png]]

![[Pasted image 20251115171508.png]]![[Pasted image 20251115171631.png]]
![[Pasted image 20251115171640.png]]

![[Pasted image 20251115171853.png]]
![[Pasted image 20251115171925.png]]
![[Pasted image 20251115171950.png]]

![[Pasted image 20251115172026.png]]


![[Pasted image 20251115172826.png]]
![[Pasted image 20251115172847.png]]

![[Pasted image 20251115173056.png]]


![[Pasted image 20251115173109.png]]
![[Pasted image 20251115173257.png]]



![[Pasted image 20251115173338.png]]
![[Pasted image 20251115173343.png]]
If any of the probabilities is 0 the entire instance will be 0
for example imagine a spam detection software trained on prev data, if none of the training data contained the word "bitcoin". Then the prediction of it will be 0 and not flag it as spam

This is why we use laplace smoothing
![[Pasted image 20251115173738.png]]
we add 1 to every instance so that it never equals 0 (we fake an appearance)
side note: 8 as denominator comes from the Yes classification that has Chinese



![[Pasted image 20251115174117.png]]
![[Pasted image 20251115174223.png]]

![[Pasted image 20251115174905.png]]

![[Pasted image 20251115175120.png]]

![[Pasted image 20251115175134.png]]



